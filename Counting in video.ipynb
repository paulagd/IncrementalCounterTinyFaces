{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/home/paula/THINKSMARTER_/Model/ExtendedTinyFaces/')\n",
    "# sys.path.append('/home/paula/THINKSMARTER_/Model/IncrementalCounterTinyFaces/')\n",
    "import evaluate as tiny_evaluate\n",
    "from metrics import *\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import detect\n",
    "from IPython import embed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVideo(dir_path, videoName):\n",
    "    \"\"\" Creates a video from the frames of a directory. \"\"\"\n",
    "    # dir_path = './output_video_sample_all_faces'\n",
    "    # videoName = 'test_ExtendedTinyFaces_allFaces.avi'\n",
    "\n",
    "    listdir = os.listdir(dir_path)\n",
    "    listdir.sort()\n",
    "    images = []\n",
    "    for f in listdir:\n",
    "        if f.endswith('.png'):\n",
    "            images.append(f)\n",
    "\n",
    "    image_path = os.path.join(dir_path, images[0])\n",
    "    frame = cv2.imread(image_path)\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Be sure to use lower case\n",
    "    out = cv2.VideoWriter(videoName, fourcc, 20.0, (width, height))\n",
    "\n",
    "    print(\"CREATING VIDEO --->\")\n",
    "    for image in tqdm(images):\n",
    "\n",
    "        image_path = os.path.join(dir_path, image)\n",
    "        frame = cv2.imread(image_path)\n",
    "\n",
    "        out.write(frame) # Write out frame to video\n",
    "        if (cv2.waitKey(1) & 0xFF) == ord('q'): # Hit `q` to exit\n",
    "            break\n",
    "\n",
    "    # Release everything if job is finished\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutVideo(video_path, t1, t2):\n",
    "    \"\"\"Cut the video on video_path between the instants t1 and t2 in seconds.\"\"\"\n",
    "\n",
    "    cap = cv2.VideoCapture('/home/paula/THINKSMARTER_/videoplayback.mp4')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    initial = fps * t1\n",
    "    final = fps * t2\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n",
    "    size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "    out = cv2.VideoWriter('test_2.avi',fourcc, fps , size)\n",
    "    count = 0\n",
    "    while(count < final):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if ret :\n",
    "            if count > initial:\n",
    "                print(count)\n",
    "                #frame = cv2.resize(frame,(size[0]//3,size[1]//3))\n",
    "                out.write(frame)\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettingFrames(clip_path):\n",
    "    \"\"\" Get all the frames and images\"\"\"\n",
    "    # clip_path =\n",
    "    cap = cv2.VideoCapture(clip_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    i = 0\n",
    "    frames = []\n",
    "    print(\"Getting all the frames ... \")\n",
    "    \n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(frame[:,:,::-1])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    images = []\n",
    "    for k in range(0, len(frames), 10):\n",
    "        try:\n",
    "            imgs = [frames[k], frames[k+1], frames[k+2], frames[k+10]]\n",
    "        except IndexError:\n",
    "            imgs = [frames[k], frames[k+1], frames[k+2], frames[len(frames)-1]]\n",
    "        images.append(imgs)\n",
    "\n",
    "    return [frames, images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrameAndNeighbourDetections(images, weights_path):\n",
    "    \"\"\" Get all the detections in images(len 26)\"\"\"\n",
    "\n",
    "    all_detections = []\n",
    "    print(\"Getting all the detections of the main frame and its neighbours --->\")\n",
    "    for row in tqdm(images):\n",
    "        detections = []\n",
    "        for frame in row:\n",
    "            with tf.Graph().as_default():\n",
    "                b = evaluate.evaluate(weight_file_path=weights_path,  img=frame)\n",
    "            detections.append(b)\n",
    "        all_detections.append(detections)\n",
    "\n",
    "    np.save('numpy_alldetections',all_detections)\n",
    "    return all_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatcheds(images,all_detections, threshold = 0.55):\n",
    "    \"\"\"Get the matcheds on the frames.\"\"\"\n",
    "    matcheds = []\n",
    "    t0 = time.time()\n",
    "    print(\"Getting matcheds ... --->\")\n",
    "    for j in tqdm(range(len(images))):\n",
    "        frames = images[j]\n",
    "        detections = all_detections[j]\n",
    "        matched = 0\n",
    "        t0bis = time.time()\n",
    "        for p in range(len(detections[0])):\n",
    "            neigh_detect, distances = detect.train_binclas(frames, detections, p)\n",
    "\n",
    "            idx_max, val_max = np.argmax(distances[:,1]), np.max(distances[:,1])\n",
    "            if val_max > threshold:\n",
    "                matched += 1\n",
    "        matcheds.append(matched)\n",
    "        t1 = time.time()\n",
    "        print('It took %.1f sec i.e %.2f/detection' % (t1-t0bis, (t1-t0bis)/len(detections[0])))\n",
    "    print('Total : %.1f' % (time.time() - t0))\n",
    "\n",
    "    np.save('matcheds',matcheds)\n",
    "    return matcheds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting(all_detections,matcheds):\n",
    "    \"\"\" Get the total of detections computed.\"\"\"\n",
    "    s = 0\n",
    "    # for j in range(10):\n",
    "    for j in range(len(all_detections)):\n",
    "        detections = all_detections[j]\n",
    "        s += len(detections[0]) - matcheds[j]\n",
    "    s += len(detections[3])\n",
    "    print ('COUNTER S : '+ str(s))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFramesDetections(frames):\n",
    "    \"\"\" Get all the detections in frames (len 260)\"\"\"\n",
    "    detections = []                     # Detections for one face of each frame\n",
    "    detections_faces = []               # Detections for all faces of each frame\n",
    "    print(\"Getting all the frames detections... --->\")\n",
    "    for i, frame in enumerate(tqdm(frames)):\n",
    "        with tf.Graph().as_default():\n",
    "            b = tiny_evaluate.evaluate(weight_file_path=weights_path, data_dir='.jpg', output_dir='', img=frame,\n",
    "                              prob_thresh=0.5, nms_thresh=0.1, lw=3,\n",
    "                              display=False, save=False, draw=False, print_=0)\n",
    "        detections.append(b[0])\n",
    "        detections_faces.append(b)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    np.save('numpy_detections_0',detections)\n",
    "    np.save('numpy_detections_justFaces',detections_faces)\n",
    "    return detections_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nbs(all_detections,matcheds):\n",
    "    \"\"\" Computes the incremental counter nbs\"\"\"\n",
    "    nbs = []\n",
    "    init = len(all_detections[0][0])\n",
    "\n",
    "    #for j in range(1, 10):\n",
    "    for j in range(1, len(all_detections)):\n",
    "        nbs.append(init)\n",
    "        detections_ = all_detections[j]\n",
    "\n",
    "        # init += len(detections_[0]) - matcheds[j-1]\n",
    "        init += len(detections_[0]) - matcheds[j]\n",
    "\n",
    "    init += len(detections_[3]) - matcheds[j]\n",
    "    nbs.append(init)\n",
    "    return nbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveFrames(frames,detections_faces, nbs, out_path):\n",
    "    \"\"\"Save all the frames with the information processed\n",
    "    (bounding boxes and incremental counter)\"\"\"\n",
    "    # k = 0\n",
    "    l = 0\n",
    "    images = []\n",
    "    ff = []\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    frames[:-2]\n",
    "\n",
    "    print(\"Saving frames ... --->\")\n",
    "    for j, frame in enumerate(tqdm(frames)):\n",
    "        img = frame.copy()\n",
    "        for detect_ in detections_faces[j]:\n",
    "            pt1, pt2 = tuple(detect_[:2]), tuple(detect_[2:])\n",
    "            cv2.rectangle(img, pt1, pt2, (255, 0, 0), 2)\n",
    "\n",
    "        bottomLeftCornerOfText = (img.shape[1]-650,img.shape[0]-50)\n",
    "        cv2.putText(img, 'Incremental count : %d' % nbs[l], bottomLeftCornerOfText , font, 1.5, (0, 255, 0), 3)\n",
    "\n",
    "        if j in range(10, 89, 9):\n",
    "        # if j in range(len(all_detections), 89, 9):\n",
    "            l += 1\n",
    "        images.append(img)\n",
    "        cv2.imwrite(out_path+'/frames_%05d.png' % j, img[:,:,::-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting all the frames ... \n"
     ]
    }
   ],
   "source": [
    "weights_path = '/home/paula/THINKSMARTER_/face-detectors/Tiny_Faces/hr_res101.pkl'\n",
    "out_path = './output_video_sample_all_faces'\n",
    "videoName = 'test_incrementalCounter_allFaces-myOne.avi'\n",
    "\n",
    "[frames, images] = gettingFrames('test.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"numpy_alldetections.npy\"):\n",
    "    all_detections = np.load('numpy_alldetections.npy')\n",
    "else:\n",
    "    all_detections = getFrameAndNeighbourDetections(images, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"matcheds.npy\"):\n",
    "    matcheds = np.load('matcheds.npy')\n",
    "else:\n",
    "    matcheds = getMatcheds(images,all_detections, threshold = 0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"numpy_detections_justFaces.npy\"):\n",
    "    # detections = np.load('numpy_detections_0.npy')\n",
    "    detections_faces = np.load('numpy_detections_justFaces.npy')\n",
    "else:\n",
    "    detections_faces = getFramesDetections(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNTER S : 222\n"
     ]
    }
   ],
   "source": [
    "max_detections = counting(all_detections,matcheds)\n",
    "nbs = compute_nbs(all_detections,matcheds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/260 [00:00<00:21, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving frames ... --->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:22<00:00, 11.53it/s]\n",
      "  1%|          | 2/260 [00:00<00:13, 19.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING VIDEO --->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:13<00:00, 18.68it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "saveFrames(frames,detections_faces, nbs, out_path)\n",
    "createVideo(out_path, videoName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
